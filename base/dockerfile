
#FROM : Docker Base Image (기반이 되는 이미지, <이미지 이름>:<태그> 형식으로 설정)
#SHELL : Default Shell 지정
#RUN : Shell Script 또는 명령을 실행
#USER : 명령 실행할 사용자 권한 지정
#WORKDIR : "RUN", "CMD", "ENTRYPOINT" 명령이 실행될 작업 디렉터리
FROM ubuntu:20.04
SHELL ["/bin/bash", "-c"]
# 패키지 관리자 업데이트
RUN apt update -y
RUN apt install wget vim unzip sudo -y
# wget : 웹에서 파일을 다운로드
# vim : 텍스트 에디터
# unzip : 알집
# sudo : sudo 명령어를 쓰기위해 설치

# 사용자 생성
RUN useradd -m big
# big passwd 없이 가능하게
RUN echo 'big     ALL=NOPASSWD: ALL' >> /etc/sudoers
# RUN, ENTRYPOINT, CMD
USER big

# big 안에서 java hadoop등 설치해서 사용할 것
WORKDIR /home/big
RUN wget https://corretto.aws/downloads/latest/amazon-corretto-11-x64-linux-jdk.tar.gz
RUN tar xvzf amazon-corretto-11-x64-linux-jdk.tar.gz

RUN rm amazon-corretto-11-x64-linux-jdk.tar.gz

# java 심볼릭링크 설정
RUN ln -s $(ls |grep 'amazon-corretto-11*') java
# ssh 설치과정
RUN sudo apt-get install ssh -y
# ssh id 생성 및 키등록
RUN ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa
# 공개키를 파일들에 뿌려줌 각 파일들에 append 시켜줌 >> 이표시는 append
RUN cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys

# 하둡 압축파일 다운로드
RUN wget https://dlcdn.apache.org/hadoop/common/hadoop-3.3.4/hadoop-3.3.4.tar.gz
RUN tar -xvzf hadoop-3.3.4.tar.gz
RUN rm hadoop-3.3.4.tar.gz
# hadoop 심볼릭 링크 설정
RUN ln -s $(ls |grep 'hadoop-3*') hadoop

# hadoop-env.sh 파일 수정 echo 로 경로내 파일로 append
RUN echo "export JAVA_HOME=/home/big/java" >> /home/big/hadoop/etc/hadoop/hadoop-env.sh

# 하둡디렉터리 생성
WORKDIR /home/big/hadoop
RUN mkdir temp pids namenode_dir secondary_dir datanode_dir logs
RUN mkdir -p yarn/logs yarn/local

RUN echo 'export JAVA_HOME=/home/big/java' >> ~/.bashrc
RUN echo 'export PATH=$PATH:$JAVA_HOME/bin' >> ~/.bashrc
RUN echo 'export HADOOP_HOME=/home/big/hadoop' >> ~/.bashrc
RUN echo 'export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop' >> ~/.bashrc
RUN echo 'export PATH=$PATH:$HADOOP_HOME/bin' >> ~/.bashrc
RUN echo 'export PATH=$PATH:$HADOOP_HOME/sbin' >> ~/.bashrc

