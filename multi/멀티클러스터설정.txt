# ls나 pwd등의 기초오류가 생긴다면 root로나가 .bashrc file을 먼저 확인 해볼 것

# 멀티 클러스터 설정
https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/ClusterSetup.html

# 싱글클러스터와 동일

core-site.xml

<property>        <name>fs.defaultFS</name>        <value>hdfs://localhost:9000</value></property>
9000번 포트는 namenode를 요청하기위한 포트
9870은 내부적으로 확인하기 위한 포트

hdfs-site.xml

<property>
        <name>dfs.namenode.name.dir</name>
        <value>/home/big/hadoop/namenode_dir</value>
</property>
<property>
        <name>dfs.datanode.data.dir</name>
        <value>/home/big/hadoop/datanode_dir</value>
</property>
<property>
        <name>dfs.datanode.http.address</name>
        <value>0.0.0.0:9864</value>
</property>

# yarn log기록을 하기위한 첫번째 property
# 마지막 property는 많은 add 기록을 stage를 나누어 기록한다
# -> 나중에 local-dir파일이 너무 커지면 열 수 조차 없어지기 때문
yarn-site.xml

        <property>
                <name>yarn.nodemanager.log-dirs</name>
                <value>file:///hadoop/yarn/logs</value>
        </property>
        <property>
                <name>yarn.resourcemanager.hostname</name>
                <value>namenode</value>
        </property>
        <property>
                <name>yarn.nodemanager.local-dirs</name>
                <value>file:///hadoop/yarn/local</value>
        </property>

mapred.xml
# 프레임워크를 yarn으로 설정해줌
<property>        <name>mapreduce.framework.name</name>        <value>yarn</value></property>

hadoop-env.xml
# HADOOP_LOG_DIR 경로 잡기export HADOOP_HOME=/home/big/hadoopexport HADOOP_LOG_DIR=${HADOOP_HOME}/logs

# workers 파일 수정
내용 상의 이름들의 컴퓨터들을 사용한다고 명시
datanode1
datanode2
datanode3

###########################################################################
# docker netword ls 네트워크 리스트 확인 및 브릿지확인
bridge 가 기본 네트워크 
-> 우리의 호스트네트워크로부터 격리되어있는 네트워크 -> port binding 필요
host 내 컴퓨터가 쓰고있는 환경

# ip 고정하여 네트워크생성 
docker network create --subnet 172.29.0.0/10 --gateway 172.29.0.1 debridge

# --subnet 
# 172.29.0.0/ 시작ip 주소
# /10 -> 10개를 만들겠다.

# --gateway ip들을 통솔하는 ip
# 네트워크로 진입하기위한 gateway ip 지정이 필요

# 172.29.0.2 ~ 172.29.0.10 9개의 ip를 부여할 수 있는 작은 네트워크를 생성
# 172.29.0.1 은 네트워크의 진입점인 게이트웨이의 ip이기 때문에 사용이 불가능 == 출입문
###########################################################################


# 컨테이너 실행 옵션
# itd에서 d: 백그라운드 실행

# namenode 메타데이터 관리 및 datanode들 관리 즉 main node!!

docker run -itd \-h namenode \--name namenode \-p 9870:9870 \-p 8088:8088 \-p 9864:9864 \
yoonthemath/mcluster


docker run -itd \-h datanode1 \--name datanode1 \-p 9861:9861 \--link namenode:namenode \
yoonthemath/mcluster

docker run -itd \-h datanode2 \--name datanode2 \-p 9862:9862 \--link namenode:namenode \
yoonthemath/mcluster

docker run -itd \-h datanode3 \--name datanode3 \-p 9863:9863 \--link namenode:namenode \
yoonthemath/mcluster

각 node마다 ssh 활성화 해주기
service ssh start

# namenode로 붙어서 datanode 불러보기

namenode 불러오기

datanode1로 쉘 통신 시도해보기
# ssh 통신시도
ssh datanode1
# 오류 어디로 통신할지 모름
# 전화번호부 만들어줌
# ip 입력 > 네임서버에서 도메인반환 > 도메인입력으로 전환

big 에서
sudo vim /etc/hosts 로 이동 후
아래와 같은 전화번호부 작성
# 172.17.0.0	gateway
172.17.0.2      namenode
172.17.0.3      datanode1
172.17.0.4      datanode2
172.17.0.5      datanode3

# datanode1 접속
ssh datanode1
# yes 입력
yes

# 이때 상황 namenode에서 datanode1로 접근

# ssh 다시 시작하기
sudo service ssh start

exit
# exit 하면 datanode1을 닫고 namenode로 이동

# datanode2 접속
ssh datanode2 

# yes 입력
yes

# 이때 상황 namenode에서 datanode2로 접근


# ssh 다시 시작하기
sudo service ssh start

exit

# 이렇게 모든 datanode들 반복


####################################
docker의 port설정 후 처리

하둡 설정 페이지 $HADOOP_CONF_DIR/
hdfs-site.xml 변경

datnode의 port를 내가만든 포트값으로 변경 후 저장
####################################

namenode로 돌아가서 big의 core-site.xml
에서 localhost을 namenode로 변경
-> namenode주

레플리케이션

docker commit namenode yooonthemath/mcluster