{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation - Action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDD Transformation\n",
    "\n",
    "-  데이터를 가공하기 위한 논리적 실행계획\n",
    "-  기존의 RDD에 연산이 반영된 새로운 RDD를 반환한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation 메서드\n",
    "\n",
    "1. filter()\n",
    "2. map()\n",
    "3. flatMap()\n",
    "4. distinct()\n",
    "5. zip()\n",
    "6. join()\n",
    "6. reduceByKey()\n",
    "7. mapValues()\n",
    "8. sortBy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation - filter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[2] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_rdd = sc.textFile('/rdd/score.txt')\n",
    "# filter()\n",
    "#필터한 엘리먼트를 다시 필터 가능\n",
    "score_rdd.filter(lambda e : '스파크' in e).filter(lambda e :'홍길' in e)\n",
    "# type(score_rdd.filter(lambda e : '스파크' in e))\n",
    "# 조건에 맞는 데이터만\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation - map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 6, 10, 14, 18]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map()\n",
    "\n",
    "# 각각의 요소에 적용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2, 6, 10, 14, 18]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원본 rdd 는 불변  덮어씌우지 않는 이상\n",
    "# score_rdd.collect()\n",
    "data = [1, 3, 5, 7, 9]\n",
    "map_rdd = sc.parallelize(data)\n",
    "map_rdd.map(lambda e: e * 2).collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation - flatMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 100, 4, 5, 6, 100, 7, 8, 9, 100]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 100, 4, 5, 6, 100, 7, 8, 9, 100]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#flatMap()\n",
    "# 각각의 요소에 함수를 적용한 다음 평면화 시켜주는 함수\n",
    "nlist = [[1, 2, 3], \n",
    "         [4, 5, 6], \n",
    "         [7, 8, 9]]\n",
    "flat_rdd = sc.parallelize(nlist)\n",
    "def append_data(e):\n",
    "    e.append(100)\n",
    "    return e\n",
    "res = flat_rdd.flatMap(lambda e :append_data(e)).collect()\n",
    "len(res)\n",
    "# flatMap은 배열의 차원 축소기능해줌\n",
    "# [[1,2,3,100],[4,5,6,100],[7,8,9,100]]\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = [[1,2,3],4,5]\n",
    "# 더 이상 축소할 게 없는 리스트(배열은) flatMap 불가능\n",
    "# sc.parallelize(tmp).flatMap(lambda e: e).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = score_rdd.flatMap(lambda e:e+'점').collect()\n",
    "res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 9:=============================================>                 (16 + 2) / 22]\r\n",
      "\r\n",
      "                                                                                      \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 연습문제 : filter, map, flatMap \n",
    "\n",
    "nlist안의 요소들중 홀수인 요소만 추출하여 100을 곱하여 list로 반환하시오  \n",
    "\n",
    " - nlist = [[[1, 2], [3, 4, 5]],[[6, 7], [8, 9, 10, 11]],[[12,13,14,15], [16, 17]]]\n",
    "\n",
    " - 결과 : [100, 300, 500, 700, 900, 1100, 1300, 1500, 1700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[100, 300, 500, 700, 900, 1100, 1300, 1500, 1700]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlist = [[[1, 2], [3, 4, 5]],[[6, 7], [8, 9, 10, 11]],[[12,13,14,15], [16, 17]]]\n",
    "flat_rdd2 = sc.parallelize(nlist)\n",
    "# 필터의 람다함수는 boolean(True or False )에서 True를 받아 반환한다.\n",
    "flat_rdd2 .flatMap(lambda e :e).\\\n",
    "flatMap(lambda e :e).\\\n",
    "filter(lambda e : e%2==1).\\\n",
    "map(lambda e : e*100).\\\n",
    "collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation - distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['안녕', '반가워', 'hello']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlist = [1, 2, 3, 1, 2, 3, 1, 2, 3 , 4, 5]\n",
    "distinct_rdd  = sc.parallelize(nlist)\n",
    "distinct_rdd.distinct().collect()\n",
    "slist = ['안녕','반가워','hello','hello']\n",
    "distinct_rdd2 = sc.parallelize(slist)\n",
    "distinct_rdd2.distinct().collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation - zip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 39:=============================>                            (1 + 1) / 2]\r",
      "\r",
      "[Stage 39:==========================================================(2 + 0) / 2]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('양식', '파스타'), ('양식', '스테이크'), ('한식', '불고기'), ('한식', '비빔밥'), ('한식', '김치')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zip() : 두 rdd를 결합해 key-value 형태의 rdd(Pair RDD)로 생성\n",
    "foods = ['파스타','스테이크', '불고기', '비빔밥', '김치']\n",
    "category = ['양식', '양식', '한식', '한식', '한식']\n",
    "\n",
    "foods_rdd = sc.parallelize(foods)\n",
    "category_rdd = sc.parallelize(category)\n",
    "zip_rdd = category_rdd.zip(foods_rdd)\n",
    "zip_rdd\n",
    "zip_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zip 결과\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('양식', '파스타'), ('양식', '스테이크'), ('한식', '불고기'), ('한식', '비빔밥'), ('한식', '김치')]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tuple의 리스트로 RDD를 생성하면 Pair RDD 가된다.\n",
    "tmp = list(map(lambda a, b : (a,b), category, foods))\n",
    "tmp_rdd = sc.parallelize(tmp)\n",
    "tmp_rdd.collect()\n",
    "\n",
    "tmp = list(zip(category, foods))\n",
    "tmp_rdd = sc.parallelize(tmp)\n",
    "print('zip 결과')\n",
    "tmp_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation - reduceByKey(), mapValues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('양식', ['파스타', '스테이크']), ('한식', ['불고기', '비빔밥', '김치'])]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reduceByKey 키값을 기준으로 value값들을 연산\n",
    "# mapValuse Pair RDD의 value들에 대해 map연산 수행\n",
    "zip_rdd.reduceByKey(lambda a, b : a + ',' + b).collect()\n",
    "res = zip_rdd.reduceByKey(lambda a, b : a + ',' + b).mapValues(lambda e : e.split(',')).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation - sortBy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('한식', ['불고기', '비빔밥', '김치']), ('양식', ['파스타', '스테이크'])]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 키값으로 내림차순\n",
    "res.sortBy(lambda e : e[0],ascending=False).collect()\n",
    "# value 값으로 오름차순\n",
    "res.sortBy(lambda e : e[1]).collect()\n",
    "# 메뉴가지수로 오름차순\n",
    "res.sortBy(lambda e : len(e[1])).collect()\n",
    "res.sortBy(lambda e : len(e[1][1])).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('양식', ['파스타', ' 스테이크']), ('한식', ['불고기', ' 비빔밥', ' 김치'])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('양식', ['파스타', ' 스테이크']), ('한식', ['불고기', ' 비빔밥', ' 김치'])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('한식', ['불고기', ' 비빔밥', ' 김치']), ('양식', ['파스타', ' 스테이크'])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 연습문제 : distinct, zip, reduceByKey, sortBy \n",
    " - hdfs의 /score.txt 파일을 읽어와 RDD로 생성하시오\n",
    " - 각 과목별 명단을 추출하시오\n",
    " - 각 과목별 평균점수를 추출하시오\n",
    " - 이때 중복으로 들어간 홍진호의 데이터는 한번만 적용되도록 합니다.  \n",
    " \n",
    " \n",
    " \n",
    " - 결과 :  \n",
    " [('스파크', {'명단': ['하명도', '홍길동', '임꺽정']}), ('텐서플로우', {'명단': ['임요환', '홍진호', '이윤열']})]       \n",
    "  \n",
    " [('스파크', {'평균점수': 63.333333333333336}), ('텐서플로우', {'평균점수': 70.66666666666667})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#txt파일 불러오기\n",
    "score_rdd = sc.textFile('/rdd/score.txt')\n",
    "\n",
    "# 중복제거\n",
    "score_rdd1=score_rdd.distinct()\n",
    "\n",
    "# 스파크, 텐서플로우 분리\n",
    "spark_rdd = score_rdd1.filter(lambda e : '스파크' in e).map(lambda e : e.split(' ')).flatMap(lambda e : e)\n",
    "tensor_rdd = score_rdd1.filter(lambda e : '텐서플로우' in e).map(lambda e : e.split(' ')).flatMap(lambda e : e)\n",
    "\n",
    "# 숫자 분리 및 숫자는 정수형으로 변환\n",
    "spark_rdd_num = spark_rdd.filter(lambda e: e.isdigit()).map(lambda e : int(e))\n",
    "spark_rdd_str = spark_rdd.filter(lambda es : not es.isdigit())\n",
    "tensor_rdd_num = tensor_rdd.filter(lambda e: e.isdigit()).map(lambda e : int(e))\n",
    "tensor_rdd_str = tensor_rdd.filter(lambda es : not es.isdigit())\n",
    "\n",
    "# 스파크 및 텐서플로우를 키로 벨류값들 모아주기\n",
    "zip_spark = spark_rdd_str.filter(lambda e : '스파크' in e).zip(spark_rdd_str.filter(lambda e : '스파크' not in e))\n",
    "zip_spark_num = spark_rdd_str.filter(lambda e : '스파크' in e).zip(spark_rdd_num)\n",
    "zip_tensor = tensor_rdd_str.filter(lambda e : '텐서' in e).zip(tensor_rdd_str.filter(lambda e : '텐서' not in e))\n",
    "zip_tensor_num = tensor_rdd_str.filter(lambda e : '텐서' in e).zip(tensor_rdd_num)\n",
    "\n",
    "# 벨류값 한개의 리스트로 합치고 dict형태로 변환\n",
    "zip_spark_fin = zip_spark.reduceByKey(lambda a, b : a + ',' + b).mapValues(lambda e : {'명단':e.split(',')})\n",
    "zip_spark_num_fin = zip_spark_num.reduceByKey(lambda a, b : a + b).mapValues(lambda e : {'평균점수':e/3})\n",
    "zip_tensor_fin = zip_tensor.reduceByKey(lambda a, b : a + ',' + b).mapValues(lambda e : {'명단':e.split(',')})\n",
    "zip_tensor_num_fin  = zip_tensor_num.reduceByKey(lambda a, b : a + b).mapValues(lambda e : {'평균점수':e/3})\n",
    "\n",
    "score_member_fin = sc.parallelize([zip_spark_fin.collect(),zip_tensor_fin.collect()]).flatMap(lambda e:e)\n",
    "score_num_fin= sc.parallelize([zip_spark_num_fin.collect(),zip_tensor_num_fin.collect()]).flatMap(lambda e:e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 394:>                                                        (0 + 2) / 2]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('스파크', {'명단': ['임꺽정', '하명도', '홍길동']}), ('텐서플로우', {'명단': ['홍진호', '임요환', '이윤열']})]\n",
      "[('스파크', {'평균점수': 63.333333333333336}), ('텐서플로우', {'평균점수': 70.66666666666667})]\n"
     ]
    }
   ],
   "source": [
    "print(score_member_fin.collect())\n",
    "print(score_num_fin.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation - join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('스파크', ({'명단': ['하명도', '홍길동', '임꺽정']}, {'평균점수': 63.333333333333336})),\n",
       " ('텐서플로우', ({'명단': ['홍진호', '임요환', '이윤열']}, {'평균점수': 70.66666666666667}))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('스파크', {'명단': ['하명도', '홍길동', '임꺽정'], '평균점수': 63.333333333333336}),\n",
       " ('텐서플로우', {'명단': ['홍진호', '임요환', '이윤열'], '평균점수': 70.66666666666667})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 스파크에서 연산은 단일 파티션에서 작동   \n",
    "\n",
    "\n",
    "- reduceByKey와 같이 특정 키에 매핑된 모든 값에 대한 연산을 수행하기 위해서는   \n",
    "  파티션에 흩어진 특정키에 해당하는 값을 하나의 파티션으로 모아 줄 필요가 있음  \n",
    "\n",
    "\n",
    "- 모든 키에 대한 모든 값을 찾기 위해 모든 파티션을 탐색하고, 해당하는 값들을 하나의 파티션으로 옮겨오는 과정을 셔플이라고 부른다.  \n",
    "\n",
    "\n",
    "- 디스크 IO 또는 네트워크 IO가 발생함으로 비용이 매우 비싼 작업  \n",
    "\n",
    "\n",
    "\n",
    "ex)   \n",
    "filter : 각 파티션에 있는 하나의 튜플에 대해 조건을 탐색하면 됨으로 셔플 발생 x  \n",
    "reduceByKey : 연산을 시작하기 위해서는 우선적으로 모든 파티션에 분산되어 있는 특정 키 값을 수집해야함으로 셔플 발생 \n",
    "- 셔플이 발생하는 함수들 :\n",
    " - subtractByKey\n",
    " - groupBy\n",
    " - foldByKey\n",
    " - reduceByKey\n",
    " - aggregateByKey\n",
    " - transformations of a join of any type\n",
    " - distinct\n",
    " - cogroup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![shuffle](./img/shuffle.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDD Action\n",
    "\n",
    "- transformation 연산을 통해 생성한 논리적 실행계획을 최적화 하여 연산을 수행. 빠른 연산이 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action Method\n",
    "\n",
    "1. collect()\n",
    "2. take()\n",
    "3. takeOrdered()\n",
    "4. top()\n",
    "5. countByValue()\n",
    "6. foreach()\n",
    "7. reduce()\n",
    "8. saveAsTextFile()\n",
    "9. max()\n",
    "10. min()\n",
    "11. mean()\n",
    "12. variance()\n",
    "13. stdev()\n",
    "14. stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action - collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['하명도 스파크 50',\n",
       " '홍길동 스파크 80',\n",
       " '임꺽정 스파크 60',\n",
       " '임요환 텐서플로우 100',\n",
       " '홍진호 텐서플로우 22',\n",
       " '홍진호 텐서플로우 22',\n",
       " '이윤열 텐서플로우 90']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action - take()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action - takeOrdered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2, 0.4]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action - top()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 3]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action - countByValues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'a': 2, 'b': 3, 'c': 2, 'd': 1})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action - reduce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action - foreach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action - saveAsTextFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"('스파크', {'명단': ['하명도', '홍길동', '임꺽정'], '평균점수': 63.333333333333336})\",\n",
       " \"('텐서플로우', {'명단': ['홍진호', '임요환', '이윤열'], '평균점수': 70.66666666666667})\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = sc.textFile(\"/rdd/rdd_prac.txt\")\n",
    "test.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action - max, min, mean, variance, stdev, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3.9999999999999996"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4.000000000000001"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(count: 7, mean: 3.9999999999999996, stdev: 2.0, max: 7, min: 1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
