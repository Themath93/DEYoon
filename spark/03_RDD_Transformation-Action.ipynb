{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation - Action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDD Transformation\n",
    "\n",
    "-  데이터를 가공하기 위한 논리적 실행계획\n",
    "-  기존의 RDD에 연산이 반영된 새로운 RDD를 반환한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation 메서드\n",
    "\n",
    "1. filter()\n",
    "2. map()\n",
    "3. flatMap()\n",
    "4. distinct()\n",
    "5. zip()\n",
    "6. join()\n",
    "6. reduceByKey()\n",
    "7. mapValues()\n",
    "8. sortBy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation - filter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[2] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_rdd = sc.textFile('/rdd/score.txt')\n",
    "# filter()\n",
    "#필터한 엘리먼트를 다시 필터 가능\n",
    "score_rdd.filter(lambda e : '스파크' in e).filter(lambda e :'홍길' in e)\n",
    "# type(score_rdd.filter(lambda e : '스파크' in e))\n",
    "# 조건에 맞는 데이터만\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation - map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map()\n",
    "\n",
    "# 각각의 요소에 적용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2, 6, 10, 14, 18]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원본 rdd 는 불변  덮어씌우지 않는 이상\n",
    "# score_rdd.collect()\n",
    "data = [1, 3, 5, 7, 9]\n",
    "map_rdd = sc.parallelize(data)\n",
    "map_rdd.map(lambda e: e * 2).collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation - flatMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 100, 4, 5, 6, 100, 7, 8, 9, 100]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 100, 4, 5, 6, 100, 7, 8, 9, 100]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#flatMap()\n",
    "# 각각의 요소에 함수를 적용한 다음 평면화 시켜주는 함수\n",
    "nlist = [[1, 2, 3], \n",
    "         [4, 5, 6], \n",
    "         [7, 8, 9]]\n",
    "flat_rdd = sc.parallelize(nlist)\n",
    "def append_data(e):\n",
    "    e.append(100)\n",
    "    return e\n",
    "res = flat_rdd.flatMap(lambda e :append_data(e)).collect()\n",
    "len(res)\n",
    "# flatMap은 배열의 차원 축소기능해줌\n",
    "# [[1,2,3,100],[4,5,6,100],[7,8,9,100]]\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = [[1,2,3],4,5]\n",
    "# 더 이상 축소할 게 없는 리스트(배열은) flatMap 불가능\n",
    "# sc.parallelize(tmp).flatMap(lambda e: e).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['하',\n",
       " '명',\n",
       " '도',\n",
       " ' ',\n",
       " '스',\n",
       " '파',\n",
       " '크',\n",
       " ' ',\n",
       " '5',\n",
       " '0',\n",
       " '점',\n",
       " '홍',\n",
       " '길',\n",
       " '동',\n",
       " ' ',\n",
       " '스',\n",
       " '파',\n",
       " '크',\n",
       " ' ',\n",
       " '8',\n",
       " '0',\n",
       " '점',\n",
       " '임',\n",
       " '꺽',\n",
       " '정',\n",
       " ' ',\n",
       " '스',\n",
       " '파',\n",
       " '크',\n",
       " ' ',\n",
       " '6',\n",
       " '0',\n",
       " '점',\n",
       " '임',\n",
       " '요',\n",
       " '환',\n",
       " ' ',\n",
       " '텐',\n",
       " '서',\n",
       " '플',\n",
       " '로',\n",
       " '우',\n",
       " ' ',\n",
       " '1',\n",
       " '0',\n",
       " '0',\n",
       " '점',\n",
       " '홍',\n",
       " '진',\n",
       " '호',\n",
       " ' ',\n",
       " '텐',\n",
       " '서',\n",
       " '플',\n",
       " '로',\n",
       " '우',\n",
       " ' ',\n",
       " '2',\n",
       " '2',\n",
       " '점',\n",
       " '홍',\n",
       " '진',\n",
       " '호',\n",
       " ' ',\n",
       " '텐',\n",
       " '서',\n",
       " '플',\n",
       " '로',\n",
       " '우',\n",
       " ' ',\n",
       " '2',\n",
       " '2',\n",
       " '점',\n",
       " '이',\n",
       " '윤',\n",
       " '열',\n",
       " ' ',\n",
       " '텐',\n",
       " '서',\n",
       " '플',\n",
       " '로',\n",
       " '우',\n",
       " ' ',\n",
       " '9',\n",
       " '0',\n",
       " '점']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = score_rdd.flatMap(lambda e:e+'점').collect()\n",
    "res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 9:=============================================>                 (16 + 2) / 22]\r\n",
      "\r\n",
      "                                                                                      \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 연습문제 : filter, map, flatMap \n",
    "\n",
    "nlist안의 요소들중 홀수인 요소만 추출하여 100을 곱하여 list로 반환하시오  \n",
    "\n",
    " - nlist = [[[1, 2], [3, 4, 5]],[[6, 7], [8, 9, 10, 11]],[[12,13,14,15], [16, 17]]]\n",
    "\n",
    " - 결과 : [100, 300, 500, 700, 900, 1100, 1300, 1500, 1700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100, 300, 500, 700, 900, 1100, 1300, 1500, 1700]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlist = [[[1, 2], [3, 4, 5]],[[6, 7], [8, 9, 10, 11]],[[12,13,14,15], [16, 17]]]\n",
    "flat_rdd2 = sc.parallelize(nlist)\n",
    "# 필터의 람다함수는 boolean(True or False )에서 True를 받아 반환한다.\n",
    "flat_rdd2 .flatMap(lambda e :e).\\\n",
    "flatMap(lambda e :e).\\\n",
    "filter(lambda e : e%2==1).\\\n",
    "map(lambda e : e*100).\\\n",
    "collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation - distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['hello', '안녕', '반가워']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlist = [1, 2, 3, 1, 2, 3, 1, 2, 3 , 4, 5]\n",
    "distinct_rdd  = sc.parallelize(nlist)\n",
    "distinct_rdd.distinct().collect()\n",
    "slist = ['안녕','반가워','hello','hello']\n",
    "distinct_rdd2 = sc.parallelize(slist)\n",
    "distinct_rdd2.distinct().collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation - zip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('양식', '파스타'), ('양식', '스테이크'), ('한식', '불고기'), ('한식', '비빔밥'), ('한식', '김치')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zip() : 두 rdd를 결합해 key-value 형태의 rdd(Pair RDD)로 생성\n",
    "foods = ['파스타','스테이크', '불고기', '비빔밥', '김치']\n",
    "category = ['양식', '양식', '한식', '한식', '한식']\n",
    "\n",
    "foods_rdd = sc.parallelize(foods)\n",
    "category_rdd = sc.parallelize(category)\n",
    "zip_rdd = category_rdd.zip(foods_rdd)\n",
    "zip_rdd\n",
    "zip_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zip 결과\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('양식', '파스타'), ('양식', '스테이크'), ('한식', '불고기'), ('한식', '비빔밥'), ('한식', '김치')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tuple의 리스트로 RDD를 생성하면 Pair RDD 가된다.\n",
    "tmp = list(map(lambda a, b : (a,b), category, foods))\n",
    "tmp_rdd = sc.parallelize(tmp)\n",
    "tmp_rdd.collect()\n",
    "\n",
    "tmp = list(zip(category, foods))\n",
    "tmp_rdd = sc.parallelize(tmp)\n",
    "print('zip 결과')\n",
    "tmp_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation - reduceByKey(), mapValues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduceByKey 키값을 기준으로 value값들을 연산\n",
    "# mapValuse Pair RDD의 value들에 대해 map연산 수행\n",
    "zip_rdd.reduceByKey(lambda a, b : a + ',' + b).collect()\n",
    "res = zip_rdd.reduceByKey(lambda a, b : a + ',' + b).mapValues(lambda e : e.split(',')).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation - sortBy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'sortBy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 키값으로 내림차순\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msortBy\u001b[49m(\u001b[38;5;28;01mlambda\u001b[39;00m e : e[\u001b[38;5;241m0\u001b[39m],ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# value 값으로 오름차순\u001b[39;00m\n\u001b[1;32m      4\u001b[0m res\u001b[38;5;241m.\u001b[39msortBy(\u001b[38;5;28;01mlambda\u001b[39;00m e : e[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mcollect()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'sortBy'"
     ]
    }
   ],
   "source": [
    "# 키값으로 내림차순\n",
    "res.sortBy(lambda e : e[0],ascending=False).collect()\n",
    "# value 값으로 오름차순\n",
    "res.sortBy(lambda e : e[1]).collect()\n",
    "# 메뉴가지수로 오름차순\n",
    "res.sortBy(lambda e : len(e[1])).collect()\n",
    "res.sortBy(lambda e : len(e[1][1])).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('양식', ['파스타', ' 스테이크']), ('한식', ['불고기', ' 비빔밥', ' 김치'])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('양식', ['파스타', ' 스테이크']), ('한식', ['불고기', ' 비빔밥', ' 김치'])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('한식', ['불고기', ' 비빔밥', ' 김치']), ('양식', ['파스타', ' 스테이크'])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 연습문제 : distinct, zip, reduceByKey, sortBy \n",
    " - hdfs의 /score.txt 파일을 읽어와 RDD로 생성하시오\n",
    " - 각 과목별 명단을 추출하시오\n",
    " - 각 과목별 평균점수를 추출하시오\n",
    " - 이때 중복으로 들어간 홍진호의 데이터는 한번만 적용되도록 합니다.  \n",
    " \n",
    " \n",
    " \n",
    " - 결과 :  \n",
    " [('스파크', {'명단': ['하명도', '홍길동', '임꺽정']}), ('텐서플로우', {'명단': ['임요환', '홍진호', '이윤열']})]       \n",
    "  \n",
    " [('스파크', {'평균점수': 63.333333333333336}), ('텐서플로우', {'평균점수': 70.66666666666667})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#txt파일 불러오기\n",
    "score_rdd = sc.textFile('/rdd/score.txt')\n",
    "\n",
    "# 중복제거\n",
    "score_rdd1=score_rdd.distinct()\n",
    "\n",
    "# 스파크, 텐서플로우 분리\n",
    "spark_rdd = score_rdd1.filter(lambda e : '스파크' in e).map(lambda e : e.split(' ')).flatMap(lambda e : e)\n",
    "tensor_rdd = score_rdd1.filter(lambda e : '텐서플로우' in e).map(lambda e : e.split(' ')).flatMap(lambda e : e)\n",
    "\n",
    "# 숫자 분리 및 숫자는 정수형으로 변환\n",
    "spark_rdd_num = spark_rdd.filter(lambda e: e.isdigit()).map(lambda e : int(e))\n",
    "spark_rdd_str = spark_rdd.filter(lambda es : not es.isdigit())\n",
    "tensor_rdd_num = tensor_rdd.filter(lambda e: e.isdigit()).map(lambda e : int(e))\n",
    "tensor_rdd_str = tensor_rdd.filter(lambda es : not es.isdigit())\n",
    "\n",
    "# 스파크 및 텐서플로우를 키로 벨류값들 모아주기\n",
    "zip_spark = spark_rdd_str.filter(lambda e : '스파크' in e).zip(spark_rdd_str.filter(lambda e : '스파크' not in e))\n",
    "zip_spark_num = spark_rdd_str.filter(lambda e : '스파크' in e).zip(spark_rdd_num)\n",
    "zip_tensor = tensor_rdd_str.filter(lambda e : '텐서' in e).zip(tensor_rdd_str.filter(lambda e : '텐서' not in e))\n",
    "zip_tensor_num = tensor_rdd_str.filter(lambda e : '텐서' in e).zip(tensor_rdd_num)\n",
    "\n",
    "# 벨류값 한개의 리스트로 합치고 dict형태로 변환\n",
    "zip_spark_fin = zip_spark.reduceByKey(lambda a, b : a + ',' + b).mapValues(lambda e : {'명단':e.split(',')})\n",
    "zip_spark_num_fin = zip_spark_num.reduceByKey(lambda a, b : a + b).mapValues(lambda e : {'평균점수':e/3})\n",
    "zip_tensor_fin = zip_tensor.reduceByKey(lambda a, b : a + ',' + b).mapValues(lambda e : {'명단':e.split(',')})\n",
    "zip_tensor_num_fin  = zip_tensor_num.reduceByKey(lambda a, b : a + b).mapValues(lambda e : {'평균점수':e/3})\n",
    "\n",
    "score_member_fin = sc.parallelize([zip_spark_fin.collect(),zip_tensor_fin.collect()]).flatMap(lambda e:e)\n",
    "score_num_fin= sc.parallelize([zip_spark_num_fin.collect(),zip_tensor_num_fin.collect()]).flatMap(lambda e:e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('스파크', {'명단': ['임꺽정', '하명도', '홍길동']}), ('텐서플로우', {'명단': ['이윤열', '임요환', '홍진호']})]\n",
      "[('스파크', {'평균점수': 63.333333333333336}), ('텐서플로우', {'평균점수': 70.66666666666667})]\n"
     ]
    }
   ],
   "source": [
    "print(score_member_fin.collect())\n",
    "print(score_num_fin.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('스파크', {'평균점수': 63.333333333333336}), ('텐서플로우', {'평균점수': 70.66666666666667})]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 람다함수의 내장함수들의 기능에 주목할 것\n",
    "\n",
    "score_rdd = sc.textFile('/rdd/score.txt')\n",
    "\n",
    "base = score_rdd.distinct() \\\n",
    "                .map(lambda e: e.split(' '))\n",
    "#Pair RDD 만들기 \n",
    "# e는 리스트형태로 RDD에 저장되어있음\n",
    "students = base.map(lambda e :(e[1],[e[0]])) \\\n",
    "                .reduceByKey(lambda a, b : a + b) \\\n",
    "                .mapValues(lambda e : {\"명단\":e})\n",
    "# students.collect()\n",
    "\n",
    "score_avg = base.map(lambda e : (e[1],[int(e[2])])) \\\n",
    "                .reduceByKey(lambda a,b : a+b) \\\n",
    "                .mapValues(lambda e : {\"평균점수\":sum(e)/len(e)} )\n",
    "\n",
    "score_avg.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation - join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('스파크', {'명단': ['하명도', '홍길동', '임꺽정'], '평균점수': 63.333333333333336}),\n",
       " ('텐서플로우', {'명단': ['임요환', '홍진호', '이윤열'], '평균점수': 70.66666666666667})]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 키를 기준으로 두 RDD를 결합\n",
    "res = students.join(score_avg)\n",
    "res.collect()\n",
    "#[('스파크', {'명단': ['임꺽정', '하명도', '홍길동'], '평균점수': 63.333333333333336}),\n",
    "# ('텐서플로우', {'명단': ['이윤열', '홍진호', '임요환'], '평균점수': 70.66666666666667})]\n",
    "\n",
    "res = students.join(score_avg) \\\n",
    "                .mapValues(lambda e : dict(e[0],평균점수=e[1]['평균점수']))\n",
    "res.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 스파크에서 연산은 단일 파티션에서 작동   \n",
    "\n",
    "\n",
    "- reduceByKey와 같이 특정 키에 매핑된 모든 값에 대한 연산을 수행하기 위해서는   \n",
    "  파티션에 흩어진 특정키에 해당하는 값을 하나의 파티션으로 모아 줄 필요가 있음  \n",
    "\n",
    "\n",
    "- 모든 키에 대한 모든 값을 찾기 위해 모든 파티션을 탐색하고, 해당하는 값들을 하나의 파티션으로 옮겨오는 과정을 셔플이라고 부른다.  \n",
    "\n",
    "\n",
    "- 디스크 IO 또는 네트워크 IO가 발생함으로 비용이 매우 비싼 작업  \n",
    "\n",
    "\n",
    "\n",
    "ex)   \n",
    "filter : 각 파티션에 있는 하나의 튜플에 대해 조건을 탐색하면 됨으로 셔플 발생 x  \n",
    "reduceByKey : 연산을 시작하기 위해서는 우선적으로 모든 파티션에 분산되어 있는 특정 키 값을 수집해야함으로 셔플 발생 \n",
    "- 셔플이 발생하는 함수들 :\n",
    " - subtractByKey\n",
    " - groupBy\n",
    " - foldByKey\n",
    " - reduceByKey\n",
    " - aggregateByKey\n",
    " - transformations of a join of any type\n",
    " - distinct\n",
    " - cogroup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![shuffle](./img/shuffle.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDD Action\n",
    "\n",
    "- transformation 연산을 통해 생성한 논리적 실행계획을 최적화 하여 연산을 수행. 빠른 연산이 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action Method\n",
    "\n",
    "1. collect()\n",
    "2. take()\n",
    "3. takeOrdered()\n",
    "4. top()\n",
    "5. countByValue()\n",
    "6. foreach()\n",
    "7. reduce()\n",
    "8. saveAsTextFile()\n",
    "9. max()\n",
    "10. min()\n",
    "11. mean()\n",
    "12. variance()\n",
    "13. stdev()\n",
    "14. stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action - collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['하명도 스파크 50',\n",
       " '홍길동 스파크 80',\n",
       " '임꺽정 스파크 60',\n",
       " '임요환 텐서플로우 100',\n",
       " '홍진호 텐서플로우 22',\n",
       " '홍진호 텐서플로우 22',\n",
       " '이윤열 텐서플로우 90']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RDD 데이터를 리스트로 반환\n",
    "score_rdd = sc.textFile('/rdd/score.txt')\n",
    "score_rdd.collect()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action - take()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take the first num elements of the RDD.\n",
    "data = [1,2,3,4,5]\n",
    "take_rdd = sc.parallelize(data)\n",
    "# 앞에서 순서대로 num개 가져옴\n",
    "take_rdd.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action - takeOrdered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 5, 20]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 기본은 오름 차순 정렬\n",
    "#  내림차순 정렬 : to_rdd.takeOrdered(4, lmabda e: -e)\n",
    "#  익명함수를 자유자재로 사용가능\n",
    "data = [1,20,50,123,12312,5,0,55]\n",
    "to_rdd = sc.parallelize(data)\n",
    "to_rdd.takeOrdered(4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action - top()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 55, 50, 5, 20]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [1,20,50,123,12312,5,0,55,'a']\n",
    "to_rdd = sc.parallelize(data)\n",
    "to_rdd.top(5, key=str)\n",
    "\n",
    "# 문자열로 나열하면 맨왼쪽 값만 참고하여 비교,\n",
    "# to_rdd.top(5, key=str)\n",
    "# ['a', 55, 50, 5, 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action - countByValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'a': 3, 'b': 1, 'c': 1, 'd': 1, 'e': 3})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RDD내의 같은 값이 몇번 중복되는지 dict형태로 반환해줌\n",
    "# defaultdict(int, {'a': 3, 'b': 1, 'c': 1, 'd': 1, 'e': 3})\n",
    "chras_rdd = sc.parallelize(['a', 'a' ,'a' ,'b' ,'c' ,'d' ,'e' ,'e' , 'e'])\n",
    "chras_rdd.countByValue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action - reduce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums = sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "nums.reduce(lambda a, b : a + b)\n",
    "# 1+2+3+4+5+6+7+8+9+10 가 내부적으로 생긴다\n",
    "# 앞의 두 개부터 더하여 그 더한 값에 그 다음 값을 더한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action - foreach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "# foreach()는 출력문을 시행하거할 때 사용 한다. 리턴은 하지 않는 함수이다.\n",
    "def f(x): \n",
    "    print(x)\n",
    "sc.parallelize([1, 2, 3, 4, 5]).foreach(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action - saveAsTextFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 람다함수의 내장함수들의 기능에 주목할 것\n",
    "\n",
    "score_rdd = sc.textFile('/rdd/score.txt')\n",
    "\n",
    "base = score_rdd.distinct() \\\n",
    "                .map(lambda e: e.split(' '))\n",
    "#Pair RDD 만들기 \n",
    "# e는 리스트형태로 RDD에 저장되어있음\n",
    "students = base.map(lambda e :(e[1],[e[0]])) \\\n",
    "                .reduceByKey(lambda a, b : a + b) \\\n",
    "                .mapValues(lambda e : {\"명단\":e})\n",
    "\n",
    "score_avg = base.map(lambda e : (e[1],[int(e[2])])) \\\n",
    "                .reduceByKey(lambda a,b : a+b) \\\n",
    "                .mapValues(lambda e : {\"평균점수\":sum(e)/len(e)} )\n",
    "\n",
    "# 키를 기준으로 두 RDD를 결합\n",
    "res = students.join(score_avg)\n",
    "\n",
    "#[('스파크', {'명단': ['임꺽정', '하명도', '홍길동'], '평균점수': 63.333333333333336}),\n",
    "# ('텐서플로우', {'명단': ['이윤열', '홍진호', '임요환'], '평균점수': 70.66666666666667})]\n",
    "\n",
    "res = students.join(score_avg) \\\n",
    "                .mapValues(lambda e : dict(e[0],평균점수=e[1]['평균점수']))\n",
    "res.saveAsTextFile('/rdd/socre_transform.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"('스파크', {'명단': ['하명도', '홍길동', '임꺽정'], '평균점수': 63.333333333333336})\",\n",
       " \"('텐서플로우', {'명단': ['임요환', '홍진호', '이윤열'], '평균점수': 70.66666666666667})\"]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = sc.textFile('/rdd/socre_transform.txt')\n",
    "test.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action - max, min, mean, variance, stdev, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(count: 7, mean: 4.0, stdev: 2.0, max: 7, min: 1)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums = sc.parallelize([1, 4, 2, 3, 7, 6, 5])\n",
    "#최대값\n",
    "nums.max()\n",
    "#최소값\n",
    "nums.min()\n",
    "#평균\n",
    "nums.mean()\n",
    "#분산\n",
    "nums.variance()\n",
    "#표준편차\n",
    "nums.stdev()\n",
    "# describe\n",
    "nums.stats()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
