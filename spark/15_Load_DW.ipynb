{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib 한글 꺠짐 방지\n",
    "# apt-get update\n",
    "# apt-get install fonts-nanum* \n",
    "# apt-get install fontconfig\n",
    "# fc-cache -fv  # font 캐시 날리기\n",
    "# rm -rf /home/hy1/.cache/matplotlib/  #matplotliob 폰트 캐시 날리기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<jemalloc>: MADV_DONTNEED does not work (memset will be used instead)\n",
      "<jemalloc>: (This is the expected behaviour if you are running under QEMU)\n"
     ]
    }
   ],
   "source": [
    "from datetime import date, datetime\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import *\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt #그래프 패키지 모듈 등록\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_std_day(befor_day):   \n",
    "    x = dt.datetime.now() - dt.timedelta(befor_day)\n",
    "    year = x.year\n",
    "    month = x.month if x.month >= 10 else '0'+ str(x.month)\n",
    "    day = x.day if x.day >= 10 else '0'+ str(x.day)  \n",
    "    return str(year)+ '-' +str(month)+ '-' +str(day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "from matplotlib import font_manager, rc\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "if platform.system() == 'Darwin':  # 맥OS \n",
    "    rc('font', family='AppleGothic')\n",
    "elif platform.system() == 'Windows':  # 윈도우\n",
    "    path = \"c:/Windows/Fonts/malgun.ttf\"\n",
    "    font_name = font_manager.FontProperties(fname=path).get_name()\n",
    "    rc('font', family=font_name)\n",
    "else:\n",
    "    rc('font', family='NanumGothic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load - DataWareHouse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JDBC DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "JDBC = {\n",
    "    'url':'jdbc:oracle:thin:@decorona_high?TNS_ADMIN=/home/big/study/db/Wallet_DECORONA'\n",
    "    ,'props':{\n",
    "        'user':'dw_de'\n",
    "       ,'password':'123qwe!@#QWE'\n",
    "    }   \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. LOC 테이블 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 0) / 1]\r",
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    }
   ],
   "source": [
    "area = spark.read.csv('/corona_data/loc/sido_area.csv', encoding='CP949', header=True)\n",
    "popu = spark.read.csv('/corona_data/loc/sido_population.csv', encoding='CP949', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o104.jdbc.\n: java.sql.SQLException: No suitable driver\n\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:298)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:107)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:107)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcOptionsInWrite.<init>(JDBCOptions.scala:218)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcOptionsInWrite.<init>(JDBCOptions.scala:222)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:46)\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:45)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:97)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:97)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:93)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:481)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:82)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:481)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:457)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:93)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:80)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:78)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:115)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:848)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:382)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:355)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\n\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:745)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m area_pop \u001b[38;5;241m=\u001b[39m area_pop\u001b[38;5;241m.\u001b[39mselect(col(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloc\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLOC\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m                                    , col(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marea\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAREA\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m                                    ,col(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPOPULATION\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m                           )\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# area_pop.show()\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43marea_pop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjdbc\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mJDBC\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLOC\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mappend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproperties\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mJDBC\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprops\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/spark/python/pyspark/sql/readwriter.py:1038\u001b[0m, in \u001b[0;36mDataFrameWriter.jdbc\u001b[0;34m(self, url, table, mode, properties)\u001b[0m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m properties:\n\u001b[1;32m   1037\u001b[0m     jprop\u001b[38;5;241m.\u001b[39msetProperty(k, properties[k])\n\u001b[0;32m-> 1038\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjdbc\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjprop\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/spark/python/pyspark/sql/utils.py:111\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m py4j\u001b[38;5;241m.\u001b[39mprotocol\u001b[38;5;241m.\u001b[39mPy4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    113\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o104.jdbc.\n: java.sql.SQLException: No suitable driver\n\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:298)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:107)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:107)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcOptionsInWrite.<init>(JDBCOptions.scala:218)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcOptionsInWrite.<init>(JDBCOptions.scala:222)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:46)\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:45)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:97)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:97)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:93)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:481)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:82)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:481)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:457)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:93)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:80)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:78)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:115)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:848)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:382)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:355)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\n\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:745)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# loc 데이터 저장\n",
    "area_pop = area.join(popu, on='loc')\n",
    "area_pop = area_pop.select(col('loc').alias('LOC')\n",
    "                                   , col('area').alias('AREA')\n",
    "                                   ,col('total').alias('POPULATION')\n",
    "                          )\n",
    "# area_pop.show()\n",
    "area_pop.write.jdbc(url=JDBC['url'], table='LOC', mode='append', properties=JDBC['props'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. CORONA_PATIENT 테이블 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+---------+------+----------+--------------+----------+\n",
      "|                 items|numOfRows|pageNo|resultCode|     resultMsg|totalCount|\n",
      "+----------------------+---------+------+----------+--------------+----------+\n",
      "|[{16, 12659, 검역, ...|      500|     1|        00|NORMAL SERVICE|     19684|\n",
      "|  [{1465, 1461477, ...|      500|     1|        00|NORMAL SERVICE|     19684|\n",
      "|[{16, 12440, 검역, ...|      500|     1|        00|NORMAL SERVICE|     19684|\n",
      "| [{1043, 868166, 충...|      500|     1|        00|NORMAL SERVICE|     19684|\n",
      "|  [{1429, 1214957, ...|      500|     1|        00|NORMAL SERVICE|     19684|\n",
      "|[{528, 687990, 전남...|      500|     1|        00|NORMAL SERVICE|     19684|\n",
      "|  [{26161, 22449475...|      500|     1|        00|NORMAL SERVICE|     19684|\n",
      "|  [{25441, 20983169...|      500|     1|        00|NORMAL SERVICE|     19684|\n",
      "| [{1376, 847452, 대...|      500|     1|        00|NORMAL SERVICE|     19684|\n",
      "|[{520, 666170, 전남...|      500|     1|        00|NORMAL SERVICE|     19684|\n",
      "|  [{5077, 4264423, ...|      500|     1|        00|NORMAL SERVICE|     19684|\n",
      "| [{1375, 842746, 대...|      500|     1|        00|NORMAL SERVICE|     19684|\n",
      "|  [{2268, 1266446, ...|      500|     1|        00|NORMAL SERVICE|     19684|\n",
      "| [{1475, 996824, 대...|      500|     1|        00|NORMAL SERVICE|     19684|\n",
      "|  [{2249, 1204102, ...|      500|     1|        00|NORMAL SERVICE|     19684|\n",
      "|[{781, 679100, 충북...|      500|     1|        00|NORMAL SERVICE|     19684|\n",
      "|[{883, 571175, 강원...|      500|     1|        00|NORMAL SERVICE|     19684|\n",
      "|  [{1427, 1196686, ...|      500|     1|        00|NORMAL SERVICE|     19684|\n",
      "| [{1492, 940948, 경...|      500|     1|        00|NORMAL SERVICE|     19684|\n",
      "|  [{5129, 4387478, ...|      500|     1|        00|NORMAL SERVICE|     19684|\n",
      "+----------------------+---------+------+----------+--------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 코로나 감염자 데이터\n",
    "path = '/corona_data/patient'\n",
    "co_patient_json = spark.read.json(path,encoding='UTF-8')\n",
    "co_patient_json.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+-----+-------+-----------+------+------------+----------+-----------+-----------+-------+----------+\n",
      "|deathCnt| defCnt|gubun|gubunCn|    gubunEn|incDec|isolClearCnt|isolIngCnt|localOccCnt|overFlowCnt|qurRate|    stdDay|\n",
      "+--------+-------+-----+-------+-----------+------+------------+----------+-----------+-----------+-------+----------+\n",
      "|      16|  12659| 검역| 隔離區|  Lazaretto|    17|           0|         0|          0|         17|      -|2022-08-25|\n",
      "|      16|  12659| 검역| 隔離區|  Lazaretto|    17|           0|         0|          0|         17|      -|2022-08-25|\n",
      "|    6715|6109867| 경기|   京畿|Gyeonggi-do| 27032|           0|         0|      27007|         25|  45040|2022-08-25|\n",
      "+--------+-------+-----+-------+-----------+------+------------+----------+-----------+-----------+-------+----------+\n",
      "only showing top 3 rows\n",
      "\n",
      "root\n",
      " |-- LOC: string (nullable = true)\n",
      " |-- DEATH_CNT: string (nullable = true)\n",
      " |-- DEF_CNT: string (nullable = true)\n",
      " |-- LOC_OCC_CNT: string (nullable = true)\n",
      " |-- QUR_RATE: string (nullable = true)\n",
      " |-- STD_DAY: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for r1 in co_patient_json.select('items').toLocalIterator():\n",
    "    # r1.에 items가 없을 경우 그냥 넘겨버리기\n",
    "    if not r1.items:\n",
    "        continue\n",
    "    for r2 in r1.items:\n",
    "        data.append(r2)\n",
    "patient_data = spark.createDataFrame(data)\n",
    "patient_data.show(3)\n",
    "co_patients = patient_data.select(\n",
    "    patient_data.gubun.alias('LOC')\n",
    "    ,patient_data.deathCnt.alias('DEATH_CNT')\n",
    "    ,patient_data.defCnt.alias('DEF_CNT')\n",
    "    ,patient_data.localOccCnt.alias('LOC_OCC_CNT')\n",
    "    ,patient_data.qurRate.alias('QUR_RATE')\n",
    "    ,patient_data.stdDay.alias('STD_DAY')\n",
    ").where(~(col('LOC').isin(['합계','검역']))).distinct()\n",
    "co_patients.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "co_patients.write.jdbc(url=JDBC['url'], table='CORONA_PATIENTS', mode='append', properties=JDBC['props'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  CORONA_VACCINE 테이블 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- data: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- loc: string (nullable = true)\n",
      " |    |    |-- v1: string (nullable = true)\n",
      " |    |    |-- v2: string (nullable = true)\n",
      " |    |    |-- v3: string (nullable = true)\n",
      " |    |    |-- v4: string (nullable = true)\n",
      " |-- meta: struct (nullable = true)\n",
      " |    |-- cols: struct (nullable = true)\n",
      " |    |    |-- loc: string (nullable = true)\n",
      " |    |    |-- v1: string (nullable = true)\n",
      " |    |    |-- v2: string (nullable = true)\n",
      " |    |    |-- v3: string (nullable = true)\n",
      " |    |    |-- v4: string (nullable = true)\n",
      " |    |-- desc: string (nullable = true)\n",
      " |    |-- std_day: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 7:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|                  data|\n",
      "+----------------------+\n",
      "|[{서울, 8340437, 82...|\n",
      "+----------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "file_name = '/corona_data/vaccine/'\n",
    "vaccine = spark.read.json(file_name, multiLine=True)\n",
    "\n",
    "vaccine.printSchema()\n",
    "vaccine.select(vaccine.data).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-------+-------+-------+----------+\n",
      "| loc|     v1|     v2|     v3|     v4|   std_day|\n",
      "+----+-------+-------+-------+-------+----------+\n",
      "|서울|8340437|8261615|6058568|1231362|2022-09-18|\n",
      "|부산|2879935|2851047|2134874| 490187|2022-09-18|\n",
      "|대구|2019298|1996365|1402789| 260381|2022-09-18|\n",
      "+----+-------+-------+-------+-------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "    # 파이썬 압축해제 키워드\n",
    "    # **kwargs => 여러 쌍의 키워드 args 가 넘어오면 받아서 dict로 반환\n",
    "    # fnc(**dict) => dict에 있는 key-value 값들이 여러쌍의 kwargs 형태로 함수에 전달\n",
    "for r1 in vaccine.select(vaccine.data, vaccine.meta.std_day).toLocalIterator():\n",
    "    for r2 in r1.data:\n",
    "        temp = r2.asDict() # 액션매서드 row객체를 dict로 반환해주는 함수 asDIct()\n",
    "        temp['std_day'] = r1['meta.std_day'] # meta데이터에있는 날짜값 std_day는 키와 벨류를 지정해서 dict에 포함시켜줌\n",
    "        data.append(Row(**temp))# Row에 **temp는 dict()을 kwargs로 전달해주는방법\n",
    "\n",
    "vaccine_data = spark.createDataFrame(data)\n",
    "vaccine_data.show(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>V_CNT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc</th>\n",
       "      <th>std_day</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">서울</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">2022-09-18</th>\n",
       "      <th>v2</th>\n",
       "      <td>8261615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v4</th>\n",
       "      <td>1231362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v1</th>\n",
       "      <td>8340437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v3</th>\n",
       "      <td>6058568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">부산</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">2022-09-18</th>\n",
       "      <th>v2</th>\n",
       "      <td>2851047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v4</th>\n",
       "      <td>490187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v1</th>\n",
       "      <td>2879935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v3</th>\n",
       "      <td>2134874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">대구</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">2022-09-18</th>\n",
       "      <th>v2</th>\n",
       "      <td>1996365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v4</th>\n",
       "      <td>260381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v1</th>\n",
       "      <td>2019298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v3</th>\n",
       "      <td>1402789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">인천</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">2022-09-18</th>\n",
       "      <th>v2</th>\n",
       "      <td>2546449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v4</th>\n",
       "      <td>396104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v1</th>\n",
       "      <td>2570971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v3</th>\n",
       "      <td>1908028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">광주</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">2022-09-18</th>\n",
       "      <th>v2</th>\n",
       "      <td>1251041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v4</th>\n",
       "      <td>234405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v1</th>\n",
       "      <td>1262686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v3</th>\n",
       "      <td>968138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">대전</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">2022-09-18</th>\n",
       "      <th>v2</th>\n",
       "      <td>1233926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v4</th>\n",
       "      <td>193829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v1</th>\n",
       "      <td>1246195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v3</th>\n",
       "      <td>907679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">울산</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">2022-09-18</th>\n",
       "      <th>v2</th>\n",
       "      <td>959274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v4</th>\n",
       "      <td>125398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v1</th>\n",
       "      <td>968616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v3</th>\n",
       "      <td>719551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">세종</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">2022-09-18</th>\n",
       "      <th>v2</th>\n",
       "      <td>294854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v4</th>\n",
       "      <td>34695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v1</th>\n",
       "      <td>298612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v3</th>\n",
       "      <td>209194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">경기</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">2022-09-18</th>\n",
       "      <th>v2</th>\n",
       "      <td>11712435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v4</th>\n",
       "      <td>1688068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v1</th>\n",
       "      <td>11828148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v3</th>\n",
       "      <td>8678460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">강원</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">2022-09-18</th>\n",
       "      <th>v2</th>\n",
       "      <td>1338994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v4</th>\n",
       "      <td>270055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v1</th>\n",
       "      <td>1350365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v3</th>\n",
       "      <td>1062198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">충북</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">2022-09-18</th>\n",
       "      <th>v2</th>\n",
       "      <td>1417015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v4</th>\n",
       "      <td>278087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v1</th>\n",
       "      <td>1429660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v3</th>\n",
       "      <td>1106015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">충남</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">2022-09-18</th>\n",
       "      <th>v2</th>\n",
       "      <td>1881852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v4</th>\n",
       "      <td>366884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v1</th>\n",
       "      <td>1899521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v3</th>\n",
       "      <td>1475649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">전북</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">2022-09-18</th>\n",
       "      <th>v2</th>\n",
       "      <td>1580606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v4</th>\n",
       "      <td>371028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v1</th>\n",
       "      <td>1593762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v3</th>\n",
       "      <td>1284213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">전남</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">2022-09-18</th>\n",
       "      <th>v2</th>\n",
       "      <td>1640127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v4</th>\n",
       "      <td>445122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v1</th>\n",
       "      <td>1654761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v3</th>\n",
       "      <td>1363331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">경북</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">2022-09-18</th>\n",
       "      <th>v2</th>\n",
       "      <td>2269467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v4</th>\n",
       "      <td>395869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v1</th>\n",
       "      <td>2293393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v3</th>\n",
       "      <td>1724688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">경남</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">2022-09-18</th>\n",
       "      <th>v2</th>\n",
       "      <td>2854198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v4</th>\n",
       "      <td>485197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v1</th>\n",
       "      <td>2883579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v3</th>\n",
       "      <td>2142332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">제주</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">2022-09-18</th>\n",
       "      <th>v2</th>\n",
       "      <td>584841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v4</th>\n",
       "      <td>92385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v1</th>\n",
       "      <td>590587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v3</th>\n",
       "      <td>437858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      V_CNT\n",
       "loc std_day                \n",
       "서울  2022-09-18 v2   8261615\n",
       "               v4   1231362\n",
       "               v1   8340437\n",
       "               v3   6058568\n",
       "부산  2022-09-18 v2   2851047\n",
       "               v4    490187\n",
       "               v1   2879935\n",
       "               v3   2134874\n",
       "대구  2022-09-18 v2   1996365\n",
       "               v4    260381\n",
       "               v1   2019298\n",
       "               v3   1402789\n",
       "인천  2022-09-18 v2   2546449\n",
       "               v4    396104\n",
       "               v1   2570971\n",
       "               v3   1908028\n",
       "광주  2022-09-18 v2   1251041\n",
       "               v4    234405\n",
       "               v1   1262686\n",
       "               v3    968138\n",
       "대전  2022-09-18 v2   1233926\n",
       "               v4    193829\n",
       "               v1   1246195\n",
       "               v3    907679\n",
       "울산  2022-09-18 v2    959274\n",
       "               v4    125398\n",
       "               v1    968616\n",
       "               v3    719551\n",
       "세종  2022-09-18 v2    294854\n",
       "               v4     34695\n",
       "               v1    298612\n",
       "               v3    209194\n",
       "경기  2022-09-18 v2  11712435\n",
       "               v4   1688068\n",
       "               v1  11828148\n",
       "               v3   8678460\n",
       "강원  2022-09-18 v2   1338994\n",
       "               v4    270055\n",
       "               v1   1350365\n",
       "               v3   1062198\n",
       "충북  2022-09-18 v2   1417015\n",
       "               v4    278087\n",
       "               v1   1429660\n",
       "               v3   1106015\n",
       "충남  2022-09-18 v2   1881852\n",
       "               v4    366884\n",
       "               v1   1899521\n",
       "               v3   1475649\n",
       "전북  2022-09-18 v2   1580606\n",
       "               v4    371028\n",
       "               v1   1593762\n",
       "               v3   1284213\n",
       "전남  2022-09-18 v2   1640127\n",
       "               v4    445122\n",
       "               v1   1654761\n",
       "               v3   1363331\n",
       "경북  2022-09-18 v2   2269467\n",
       "               v4    395869\n",
       "               v1   2293393\n",
       "               v3   1724688\n",
       "경남  2022-09-18 v2   2854198\n",
       "               v4    485197\n",
       "               v1   2883579\n",
       "               v3   2142332\n",
       "제주  2022-09-18 v2    584841\n",
       "               v4     92385\n",
       "               v1    590587\n",
       "               v3    437858"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# column 을 rowfh : stack\n",
    "# row를 column으로 : pivot\n",
    "# 진짜 판다스객체로 만들면 spark와 하둡의 데이터 병렬처리의 이점을 얻을 수 없다.\n",
    "pd_vaccine = vaccine_data.to_pandas_on_spark()\n",
    "pd_vaccine = pd_vaccine.set_index(['loc','std_day'])\n",
    "# 복합키를 인덱스로  하고 나머지를 stack하면 row형태로 변환됨\n",
    "pd_vaccine = pd_vaccine.stack()\n",
    "# # 보기편하게 만들어보기\n",
    "pd_vaccine = pd_vaccine.to_dataframe('V_CNT')\n",
    "# 위의  값은 타입이 pandas의series임 다시 spark형태로 변환필요\n",
    "pd_vaccine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 멀티인덱스 확인후 각자 로 뜯어주기\n",
    "# print(pd_vaccine.index)\n",
    "# 복합키 뜯어주기 resset_index() 판다스 데이터프레임에 사용\n",
    "pd_vaccine = pd_vaccine.reset_index().rename(columns={\"level_2\":\"V_TH\"})\n",
    "# print(pd_vaccine.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+----+-------+\n",
      "| loc|   std_day|V_TH|  V_CNT|\n",
      "+----+----------+----+-------+\n",
      "|서울|2022-09-18|  v2|8261615|\n",
      "|서울|2022-09-18|  v4|1231362|\n",
      "|서울|2022-09-18|  v1|8340437|\n",
      "+----+----------+----+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vaccine_data = pd_vaccine.to_spark()\n",
    "vaccine_data = vaccine_data.drop('level_0','index')\n",
    "vaccine_data.show(3)\n",
    "vaccine_data = vaccine_data.select(vaccine_data.loc.alias('LOC'),vaccine_data.std_day.alias('STD_DAY'),\n",
    "                   vaccine_data.V_TH, vaccine_data.V_CNT)\n",
    "type(vaccine_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "vaccine_data.write.jdbc(url=JDBC['url'], table='CORONA_VACCINE', mode='append', properties=JDBC['props'])\n",
    "## 안되는이유 숫자에 쉼표가 들어가 있어서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------+----------------+--------------+------+\n",
      "| _c0| _c1|   _c2|             _c3|           _c4|   _c5|\n",
      "+----+----+------+----------------+--------------+------+\n",
      "|연도|광역|시군구|          시설명|사업자등록번호|시설군|\n",
      "|2020|강원|강릉시|(주)경포솔향온천|  127-86-57613|목욕장|\n",
      "|2020|강원|강릉시|  24시황실사우나|  226-33-03247|목욕장|\n",
      "+----+----+------+----------------+--------------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_name = '/corona_data/loc/전국다중이용시설.csv'\n",
    "fac = spark.read.csv(file_name, encoding='CP949')\n",
    "fac.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 37:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| LOC|FAC_CNT|\n",
      "+----+-------+\n",
      "|경북|    944|\n",
      "|대전|    767|\n",
      "|전북|    759|\n",
      "|충북|    617|\n",
      "|울산|    431|\n",
      "|경남|   1357|\n",
      "|제주|    310|\n",
      "|충남|    824|\n",
      "|전남|    825|\n",
      "|인천|   1386|\n",
      "|부산|   1462|\n",
      "|대구|   1015|\n",
      "|경기|   6303|\n",
      "|서울|   5224|\n",
      "|광주|    732|\n",
      "|세종|    243|\n",
      "|강원|    584|\n",
      "+----+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 37:==========================================================(1 + 0) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# fac=fac.select(fac._c1.alias('LOC'),fac._c3.alias('fac_name'))\n",
    "# fac.show(3)\n",
    "\n",
    "fac_data = fac.groupBy(fac.LOC).agg(count(fac.LOC).alias('FAC_CNT')).select('*').where(col('LOC')!= '광역')\n",
    "\n",
    "fac_data.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. LOC_FACILITY_CNT\t테이블 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "fac_data.write.jdbc(url=JDBC['url'], table='LOC_FACILITY_CNT', mode='append', properties=JDBC['props'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "377b85fccf01b1fe6a959144825e6c17ac3718c2615da119d71a1f46ada91329"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
